#!/usr/bin/env groovy
/**
 * Executes a list of jobs either in parallel or sequentially.
 *
 * Supports multiple invocation styles:
 * 1. Old Way with Select:
 * stdRun(block: 'bootstrap', action: 'init', select: [key1: value1, key2: '!value2'], parallel: false)
 * 2. New Way:
 * stdRun(jobNames: ['job1', 'job2'], parallel: true)
 *
 * @param params A map of parameters. Can include:
 * - block: The block to filter (Old Way)
 * - action: The action within the block (Old Way)
 * - select: A map of key-value pairs to filter tasks (supports '!' for inequality)
 * - jobNames: A list of jobNames to execute (New Way)
 * - parallel: Boolean indicating parallel execution (default: true)
 */
def call(Map params = [:]) {
    script {
        loadResourceScript "execute.sh"
        def parallelFlag = params.get('parallel', true)
        // Ensure a tmp dir exists on this node session
        env.TMP_DIR = pwd(tmp:true)
       
        // Make sure outputs.json is available on this node
        ensureOutputsJson()
        // Set global environment variables (also decides cross-node import behavior)
        setGlobalEnvVars()
        // Read the outputs.json file generated by stdDiscover
        def hits = readHitsJson()
        // Retrieve tasks based on provided parameters
        def tasks = getTasks(hits, params)
        if (tasks.isEmpty()) {
            catchError(buildResult: 'SUCCESS', stageResult: 'UNSTABLE') {
                error "No tasks to execute for the given parameters."
            }
            return
        }
        // Execute the tasks
        executeTasks(tasks, parallelFlag)
    }
}
/**
 * Sets the global environment variables required for task execution.
 */
def setGlobalEnvVars() {
    env.PRJ_ROOT = pwd()
    env.PRJ_DATA_HOME = "${env.TMP_DIR}/.data"
    env.PRJ_CACHE_HOME = "${env.TMP_DIR}/.cache"
    env.PRJ_CONFIG_HOME = "${env.TMP_DIR}/.config"
    env.PRJ_RUNTIME_DIR = "${env.TMP_DIR}/.run"
    env.PRJ_PATH = "${env.TMP_DIR}/.bin"
    env.TERM = "xterm-256color"
    // Heuristic: if Discover ran on a different node, import drvs via SSH from discovery host
    def sameNode = (env.STD_DISCOVERY_NODE && env.STD_DISCOVERY_NODE == env.NODE_NAME)
    env.DRV_IMPORT_FROM_DISCOVERY = sameNode ? false : (env.STD_OUTPUTS_JSON ? true : false)
    env.REMOTE_STORE = false
    env.EVALSTORE_IMPORT = "${env.TMP_DIR}/eval-store"
}
/**
 * Reads the hits JSON file and returns its content.
 *
 * @return The content of the hits JSON file as a Map.
 */
def readHitsJson() {
    def hitsFile = "${env.TMP_DIR}/outputs.json"
    if (!fileExists(hitsFile)) {
        error "File '${hitsFile}' does not exist. Ensure 'Discover' ran earlier or provide STD_OUTPUTS_JSON."
    }
    return readJSON(file: hitsFile)
}
/**
 * Retrieves tasks based on provided parameters.
 *
 * @param hits The content of the hits JSON file.
 * @param params The parameters map.
 * @return A list of tasks to execute.
 */
def getTasks(hits, Map params) {
    if (params.containsKey('jobNames')) {
        // New Way: Retrieve tasks by jobNames
        return getTasksByJobNames(hits, params.jobNames)
    } else if (params.containsKey('block') && params.containsKey('action')) {
        // Old Way: Retrieve tasks by block and action, with optional select criteria
        return getTasksByBlockAndAction(hits, params.block, params.action, params.get('select', [:]))
    } else {
        error "Invalid parameters for stdRun. Provide either 'jobNames' or both 'block' and 'action'."
    }
}
/**
 * Retrieves tasks based on job names.
 *
 * @param hits The content of the hits JSON file.
 * @param jobNames The list of job names.
 * @return A list of tasks to execute.
 */
def getTasksByJobNames(hits, jobNames) {
    if (!(jobNames instanceof List)) {
        error "Parameter 'jobNames' must be a list of strings."
    }
    if (jobNames.isEmpty()) {
        echo "The 'jobNames' list is empty. No tasks to execute."
        return []
    }
    def tasks = []
    jobNames.each { jobName ->
        def task = findTaskByJobName(hits, jobName)
        if (!task) {
            echo "WARNING: Job with jobName '${jobName}' not found in outputs.json. Skipping."
        } else {
            tasks << task
        }
    }
    if (tasks.isEmpty()) {
        catchError(buildResult: 'SUCCESS', stageResult: 'UNSTABLE') {
            error "No jobs found matching the provided jobNames."
        }
    }
    return tasks
}
/**
 * Finds a task by job name within the hits JSON content.
 *
 * @param hits The content of the hits JSON file.
 * @param jobName The job name to search for.
 * @return The task object if found, null otherwise.
 */
def findTaskByJobName(hits, jobName) {
    // Iterate over all blocks and actions to find the task with the given jobName
    hits.values().findResult { block ->
        block.values().findResult { actionTasks ->
            actionTasks.find { task -> task.jobName == jobName }
        }
    }
}
/**
 * Retrieves tasks based on block, action, and optional select criteria.
 *
 * @param hits The content of the hits JSON file.
 * @param block The block name.
 * @param action The action name.
 * @param select A map of key-value pairs for additional filtering (supports '!' for inequality).
 * @return A list of tasks to execute.
 */
def getTasksByBlockAndAction(hits, block, action, select = [:]) {
    def tasks = []
    if (!hits.containsKey(block)) {
        catchError(buildResult: 'SUCCESS', stageResult: 'UNSTABLE') {
            echo "WARNING: Block '${block}' does not exist in the hits JSON. No tasks to execute."
            error "Block '${block}' does not exist."
        }
        return tasks
    }
    if (!hits[block].containsKey(action)) {
        catchError(buildResult: 'SUCCESS', stageResult: 'UNSTABLE') {
            echo "WARNING: Action '${action}' does not exist within block '${block}' in the hits JSON. No tasks to execute."
            error "Action '${action}' does not exist in block '${block}'."
        }
        return tasks
    }
    tasks = hits[block][action]
    // Apply select filters if provided
    if (select && select instanceof Map) {
        tasks = tasks.findAll { task ->
            // For each key-value pair in select, check if the task matches the condition
            select.every { key, value ->
                if (!task.containsKey(key)) {
                    return false
                }
                if (value instanceof String && value.startsWith('!')) {
                    // Negative condition (not equal to)
                    def actualValue = value.substring(1)
                    return task[key] != actualValue
                } else {
                    // Positive condition (equal to)
                    return task[key] == value
                }
            }
        }
    }
    if (tasks.isEmpty()) {
        catchError(buildResult: 'SUCCESS', stageResult: 'UNSTABLE') {
            error "No tasks found matching the criteria."
        }
    }
    return tasks
}
/**
 * Executes the provided tasks either in parallel or sequentially.
 *
 * @param tasks List of task objects to execute.
 * @param isParallel Boolean indicating if tasks should run in parallel.
 */
def executeTasks(List tasks, Boolean isParallel) {
    // Ensure all tasks have unique jobNames
    def jobNames = tasks.collect { it.jobName }
    def duplicateJobNames = jobNames.findAll { jobName -> jobNames.count(jobName) > 1 }.unique()
    if (duplicateJobNames) {
        error "Duplicate job names found: ${duplicateJobNames.join(', ')}. Ensure each job has a unique name."
    }
    if (tasks.isEmpty()) {
        catchError(buildResult: 'SUCCESS', stageResult: 'UNSTABLE') {
            error "No tasks to execute after filtering."
        }
        return
    }
    if (isParallel && tasks.size() > 1) {
        // Build taskMap with jobNames as keys and closures as values
        Map taskMap = tasks.collectEntries { task ->
            def jobName = task.jobName
            if (!jobName) {
                error "Each task must have a 'jobName'."
            }
            [(jobName): createTaskClosure(task, true)]
        }
        // Execute all tasks in parallel
        echo "Executing ${taskMap.size()} tasks in parallel."
        parallel(taskMap)
    } else {
        // Execute tasks sequentially without creating additional stages
        echo "Executing ${tasks.size()} tasks sequentially."
        for (def task : tasks) {
            def taskClosure = createTaskClosure(task, false)
            taskClosure.call()
        }
    }
}
/**
 * Creates a closure for executing a task.
 *
 * @param task The task object.
 * @param createStage Boolean indicating whether to create a stage for the task.
 * @return A closure that executes the task when called.
 */
def createTaskClosure(task, createStage = true) {
    def envVars = buildEnvVars(task)
    def jobName = task.jobName
    return {
        withEnv(envVars) {
            if (createStage) {
                stage(jobName) {
                    def exitCode = sh(
                        label: "${jobName}",
                        script: "bash ./execute.sh",
                        returnStatus: true
                    )
                    handleExitCode(exitCode, jobName)
                }
            } else {
                def exitCode = sh(
                    label: "${jobName}",
                    script: "bash ./execute.sh",
                    returnStatus: true
                )
                handleExitCode(exitCode, jobName)
            }
        }
    }
}
/**
 * Handles the exit code from the executed command.
 *
 * @param exitCode The exit code from the sh command.
 * @param jobName The name of the job for logging.
 */
def handleExitCode(int exitCode, String jobName) {
    switch (exitCode) {
        case 0:
            echo "${jobName} succeeded (code 0)"
            break
        case 130:
            catchError(buildResult: 'SUCCESS', stageResult: 'UNSTABLE') {
                error "${jobName} unstable (code 130)"
            }
            break
        case 131:
            catchError(buildResult: 'ABORTED', stageResult: 'ABORTED') {
                error "${jobName} aborted (code 131)"
            }
            break
        case 132:
            catchError(buildResult: 'SUCCESS', stageResult: 'NOT_BUILT') {
                error "${jobName} skipped (code 132)"
            }
            break
        default:
            error "${jobName} failed (code ${exitCode})"
    }
}
/**
 * Builds environment variables for a task.
 *
 * @param task The task object.
 * @return A list of environment variable strings in the format 'KEY=VALUE'.
 */
def buildEnvVars(task) {
    def baseEnvVars = [
        "action=${task.action}",
        "target=${task.name}",
        "cell=${task.cell}",
        "block=${task.block}",
        "actionDrv=${task.actionDrv}"
    ]
    // Include any additional environment variables specified in the task
    def additionalEnvVars = task.get("envConfig", [])
    return baseEnvVars + additionalEnvVars
}
// Ensure outputs.json is present on this node.
// If missing and STD_OUTPUTS_JSON is available in the environment, write it.
def ensureOutputsJson() {
    def hitsFile = "${env.TMP_DIR}/outputs.json"
    if (fileExists(hitsFile)) {
        return
    }
    def json = env.STD_OUTPUTS_JSON
    if (json) {
        writeFile file: hitsFile, text: json.trim()
        return
    }
    // Nothing we can do
    error "outputs.json not found and STD_OUTPUTS_JSON not provided. Run stdDiscover first in this build."
}
